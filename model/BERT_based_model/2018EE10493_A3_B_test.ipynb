{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2018EE10493_A3_B_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDce-oZ-7QP3",
        "outputId": "95a2b5a6-3a34-4110-9442-63c5bd0d380e"
      },
      "source": [
        "## DONT CHANGE THIS CELL \n",
        "# this is currently the same as dev.data.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 17:31:15--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt [following]\n",
            "--2021-10-25 17:31:16--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 63639 (62K) [text/plain]\n",
            "Saving to: ‘test.data.txt’\n",
            "\n",
            "test.data.txt       100%[===================>]  62.15K  86.0KB/s    in 0.7s    \n",
            "\n",
            "2021-10-25 17:31:18 (86.0 KB/s) - ‘test.data.txt’ saved [63639/63639]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpJcrEM18JSC",
        "outputId": "d8e7efb3-fd5c-42ef-f260-c14e95b830de"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=11BItpIV77eMRIAEIbvzb9t4F-H--IHuj"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11BItpIV77eMRIAEIbvzb9t4F-H--IHuj\n",
            "To: /content/2018EE10493_B_model.zip\n",
            "100% 1.48G/1.48G [00:14<00:00, 104MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXd02s18f0C",
        "outputId": "a626f627-3cc1-4a61-916c-66e84540ac10"
      },
      "source": [
        "!unzip ./2018EE10493_B_model.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./2018EE10493_B_model.zip\n",
            " extracting: data.zip                \n",
            "   creating: FINAL_MODEL/\n",
            "   creating: FINAL_MODEL/model/\n",
            "  inflating: FINAL_MODEL/model/config.json  \n",
            "  inflating: FINAL_MODEL/model/pytorch_model.bin  \n",
            "  inflating: FINAL_MODEL/model/training_args.bin  \n",
            "   creating: FINAL_MODEL/tokenizer/\n",
            "  inflating: FINAL_MODEL/tokenizer/tokenizer_config.json  \n",
            "  inflating: FINAL_MODEL/tokenizer/special_tokens_map.json  \n",
            "  inflating: FINAL_MODEL/tokenizer/vocab.txt  \n",
            "  inflating: FINAL_MODEL/tokenizer/tokenizer.json  \n",
            "   creating: NLP_A3/\n",
            "   creating: NLP_A3/data/\n",
            "   creating: NLP_A3/data/train/\n",
            "  inflating: NLP_A3/data/train/train.gold.txt  \n",
            "  inflating: NLP_A3/data/train/train.data.txt  \n",
            "   creating: NLP_A3/data/validation/\n",
            "  inflating: NLP_A3/data/validation/validation.data.txt  \n",
            "  inflating: NLP_A3/data/validation/validation.gold.txt  \n",
            "   creating: saved_model/\n",
            "   creating: saved_model/runs/\n",
            "   creating: saved_model/runs/Oct25_16-56-16_e6d9d5d3a244/\n",
            "  inflating: saved_model/runs/Oct25_16-56-16_e6d9d5d3a244/events.out.tfevents.1635181056.e6d9d5d3a244.77.0  \n",
            "   creating: saved_model/runs/Oct25_16-56-16_e6d9d5d3a244/1635181056.4553273/\n",
            "  inflating: saved_model/runs/Oct25_16-56-16_e6d9d5d3a244/1635181056.4553273/events.out.tfevents.1635181056.e6d9d5d3a244.77.1  \n",
            "  inflating: saved_model/runs/Oct25_16-56-16_e6d9d5d3a244/events.out.tfevents.1635181649.e6d9d5d3a244.77.2  \n",
            "   creating: saved_model/checkpoint-2000/\n",
            "  inflating: saved_model/checkpoint-2000/config.json  \n",
            "  inflating: saved_model/checkpoint-2000/pytorch_model.bin  \n",
            "  inflating: saved_model/checkpoint-2000/training_args.bin  \n",
            "  inflating: saved_model/checkpoint-2000/optimizer.pt  \n",
            "  inflating: saved_model/checkpoint-2000/scheduler.pt  \n",
            "  inflating: saved_model/checkpoint-2000/trainer_state.json  \n",
            "  inflating: saved_model/checkpoint-2000/rng_state.pth  \n",
            "   creating: saved_model/runs/Oct25_17-15-06_d097ed160b45/\n",
            "  inflating: saved_model/runs/Oct25_17-15-06_d097ed160b45/events.out.tfevents.1635182186.d097ed160b45.86.0  \n",
            "   creating: saved_model/runs/Oct25_17-15-06_d097ed160b45/1635182186.3224423/\n",
            "  inflating: saved_model/runs/Oct25_17-15-06_d097ed160b45/1635182186.3224423/events.out.tfevents.1635182186.d097ed160b45.86.1  \n",
            "  inflating: saved_model/runs/Oct25_17-15-06_d097ed160b45/events.out.tfevents.1635182793.d097ed160b45.86.2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O0tQ7cM85yO"
      },
      "source": [
        "test_data_path = '/content/test.data.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND9AbtCU_N-q"
      },
      "source": [
        "## Import relevant packages\n",
        "\n",
        "import os\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import logging\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from pdb import set_trace"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60XU_McW_Q1v"
      },
      "source": [
        "import zipfile\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gK-TcMO9Rgo",
        "outputId": "d7dad164-06f9-478c-f48f-0e539b71fe82"
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFZB_B2T9JmY"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ney3CK_3-Vs7"
      },
      "source": [
        "tokenizer_test = AutoTokenizer.from_pretrained(\"/content/FINAL_MODEL/tokenizer\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GvLjhJC8_DV"
      },
      "source": [
        "model_test = AutoModelForSequenceClassification.from_pretrained(\"/content/FINAL_MODEL/model\",num_labels=2 )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6zv16Bd-eZz"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF8DUAeF-sXG"
      },
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57i7dbqW-iF4"
      },
      "source": [
        "class Customed_Dataset(Dataset):\n",
        "  def __init__(self, X, y = None):\n",
        "    self.text_encodings = X\n",
        "    self.labels = y\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    sample = {k: torch.tensor(v[index]) for k , v in self.text_encodings.items()}\n",
        "    if self.labels:\n",
        "      sample['labels'] = torch.tensor(self.labels[index])\n",
        "\n",
        "    return sample\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.text_encodings['input_ids'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX7465KF9ESC"
      },
      "source": [
        "def Dataset(tokenizer):\n",
        "  file_v = pd.read_csv(test_data_path,sep='\\t', header = None, names = ['word', 'POS', 'index_sent1', 'sent1', 'sent2'])\n",
        "  X_test = tokenizer(list(file_v['sent1']), list(file_v['sent2']) , padding = True, truncation = True)\n",
        "  \n",
        "  test_dataset = Customed_Dataset(X_test)\n",
        "\n",
        "  return test_dataset"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKjwkziv-C88"
      },
      "source": [
        "test_dataset = Dataset(tokenizer_test)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAc-WW3Z-9AN"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_PYl_Wf---N"
      },
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    pred, labels = eval_pred\n",
        "    pred = np.argmax(pred, axis=1)\n",
        "    dict_metric = {}\n",
        "\n",
        "    dict_metric[\"accuracy\"] = accuracy_score(y_true=labels, y_pred=pred)\n",
        "    dict_metric[\"recall\"] = recall_score(y_true=labels, y_pred=pred)\n",
        "    dict_metric[\"precision\"] = precision_score(y_true=labels, y_pred=pred)\n",
        "    dict_metric[\"f1\"] = f1_score(y_true=labels, y_pred=pred)\n",
        "\n",
        "    return dict_metric"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdpG4_NN-cTp"
      },
      "source": [
        "trainer1 = Trainer(model = model_test,compute_metrics=compute_metrics)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Z2BBT7UB_Cxc",
        "outputId": "afb66823-b4b5-4581-b31a-873de192f138"
      },
      "source": [
        "output, _, _ = trainer1.predict(test_dataset)\n",
        "y_pred = np.argmax(output, axis = 1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 638\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 02:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzN_-qe5_IjU"
      },
      "source": [
        "with open('output.txt', \"w\") as output_file:\n",
        "  for y in y_pred:\n",
        "    if y == 1:\n",
        "      Y_write = 'T'\n",
        "    elif y == 0:\n",
        "      Y_write = 'F'\n",
        "    output_file.write(\"%s\\n\" % Y_write)\n",
        "  output_file.close()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeEGsTI7_4RW",
        "outputId": "77e96fe5-2e04-4781-daa6-dc9476991d62"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "# Your testing code must produce a file output.txt with predictions as T and F in each line\n",
        "\n",
        "## Final Evaluation \n",
        "# this is currently the same as dev.gold.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
        "correct, total = 0., 0.\n",
        "for prediction, gold in zip(open('output.txt'), open('test.gold.txt')):\n",
        "  prediction, gold = prediction.strip(), gold.strip()\n",
        "  total += 1\n",
        "  if prediction == gold:\n",
        "    correct += 1\n",
        "\n",
        "## Report this as the final validation performance \n",
        "print('Performance = ', (correct/total))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 17:35:34--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt [following]\n",
            "--2021-10-25 17:35:35--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1276 (1.2K) [text/plain]\n",
            "Saving to: ‘test.gold.txt’\n",
            "\n",
            "test.gold.txt       100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-25 17:35:36 (34.8 MB/s) - ‘test.gold.txt’ saved [1276/1276]\n",
            "\n",
            "Performance =  0.7053291536050157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5pm3b61_8Tt"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}