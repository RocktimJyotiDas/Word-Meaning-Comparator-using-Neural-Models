{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2018EE10493_A3_A_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSkHozvq7gGh"
      },
      "source": [
        "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
        "\n",
        "Give editor access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPmKrdbC48JU",
        "outputId": "27bdc8bb-5a9e-4c40-bc4d-411bf88434b1"
      },
      "source": [
        "## DONT CHANGE THIS CELL \n",
        "# this is currently the same as dev.data.txt\n",
        "# !wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.data.txt\n",
        "!wget --no-check-certificate www.cse.iitd.ac.in/~kskeshav/test.data.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 11:39:38--  http://www.cse.iitd.ac.in/~kskeshav/test.data.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~kskeshav/test.data.txt [following]\n",
            "--2021-10-28 11:39:39--  https://www.cse.iitd.ac.in/~kskeshav/test.data.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 138961 (136K) [text/plain]\n",
            "Saving to: ‘test.data.txt’\n",
            "\n",
            "test.data.txt       100%[===================>] 135.70K   244KB/s    in 0.6s    \n",
            "\n",
            "2021-10-28 11:39:40 (244 KB/s) - ‘test.data.txt’ saved [138961/138961]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNqC5cADNUDW",
        "outputId": "d4a67318-5f63-4d25-bb88-e9e66c62fc9e"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1xRfEBiybZwKKzIQOxEAGECgNeFr-mkXJ"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xRfEBiybZwKKzIQOxEAGECgNeFr-mkXJ\n",
            "To: /content/2018EE10493_A_model.zip\n",
            "100% 27.1M/27.1M [00:00<00:00, 127MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnrn0L-1eU7e",
        "outputId": "11d88283-3f2d-4ae3-fabf-8fa7ef1d02be"
      },
      "source": [
        "!unzip ./2018EE10493_A_model.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./2018EE10493_A_model.zip\n",
            " extracting: data.zip                \n",
            "   creating: NLP_A3/\n",
            "   creating: NLP_A3/data/\n",
            "   creating: NLP_A3/data/train/\n",
            "  inflating: NLP_A3/data/train/train.gold.txt  \n",
            "  inflating: NLP_A3/data/train/train.data.txt  \n",
            "   creating: NLP_A3/data/validation/\n",
            "  inflating: NLP_A3/data/validation/validation.data.txt  \n",
            "  inflating: NLP_A3/data/validation/validation.gold.txt  \n",
            "   creating: results/\n",
            "   creating: results/lstm/\n",
            "   creating: results/lstm/mnli/\n",
            "  inflating: results/lstm/mnli/best-lstm-mnli-params.pt  \n",
            "  inflating: results/lstm/mnli/train.log  \n",
            "  inflating: results/lstm/mnli/vocab  \n",
            "  inflating: train_pos.json          \n",
            "  inflating: valid_pos.json          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtiPw4zYf7o3"
      },
      "source": [
        "test_data_path = '/content/test.data.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qApqS2y-jzn-"
      },
      "source": [
        "model_file_path = './results/lstm/mnli'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohCJXD4Yj4Au"
      },
      "source": [
        "import dill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHrAwRtzj9UW"
      },
      "source": [
        "## Import relevant packages\n",
        "\n",
        "import os\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.optim as O\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "import logging\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "from pdb import set_trace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnima-mhkDyX"
      },
      "source": [
        "import zipfile\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do_2atSVjUeV"
      },
      "source": [
        "with open(os.path.join(model_file_path, \"vocab\"), 'rb') as f:\n",
        "  sent = dill.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAvxkk-ni8tE"
      },
      "source": [
        "def Dataset(batch_size, sent):\n",
        "  file_ = pd.read_csv(test_data_path,sep='\\t', header = None, names = ['word', 'POS', 'index_sent1', 'sent1', 'sent2'])\n",
        "  file_['index_sent2'] = file_['index_sent1']\n",
        "  for i in file_.index:\n",
        "    idx1 = file_.at[i, 'index_sent1']\n",
        "    file_.at[i, 'index_sent1'] = idx1[0]\n",
        "    idx2 = file_.at[i, 'index_sent2']\n",
        "    file_.at[i, 'index_sent2'] = idx2[-1]\n",
        "  for i in file_.index:\n",
        "    idx1 = file_.at[i, 'POS']\n",
        "    if idx1[0] == 'N':\n",
        "      file_.at[i, 'POS'] = 1\n",
        "    else:\n",
        "      file_.at[i, 'POS'] = 0\n",
        "  file_.to_json('test_pos.json', orient = 'records', lines = True)\n",
        "  load_model_lemma = spacy.load('en', disable = ['parser','ner'])\n",
        "  def tokenize_lemma(text):\n",
        "    doc = load_model_lemma(text)\n",
        "    return [token.lemma_ for token in doc]\n",
        "\n",
        "  idx_sent = Field(sequential=False, use_vocab=False)\n",
        "  sent = sent\n",
        "  category = Field(sequential=False, use_vocab=False)\n",
        "  fields = {'word': ('w', sent), \"POS\":(\"pos\", category), \"index_sent1\": ('idx1', idx_sent), \"index_sent2\": ('idx2', idx_sent), \"sent1\":('s1', sent), \"sent2\":('s2',sent)}\n",
        "  test_data = TabularDataset.splits(path=\"\", train=\"test_pos.json\", format=\"json\", fields=fields)\n",
        "\n",
        "  test_iterator = BucketIterator.splits(test_data, batch_size=batch_size, device=\"cuda\", sort_key = lambda x: len(x.s1), sort_within_batch=False, shuffle=False)[0]\n",
        "  return test_iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFEmpJ9llCHe"
      },
      "source": [
        "test_iter = Dataset(128, sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngKnRRIgu20b"
      },
      "source": [
        "def adjust_dim(word_idx, hidden_size):\n",
        "  word_idx = torch.unsqueeze(word_idx, 0)\n",
        "  word_idx = torch.unsqueeze(word_idx, 2)\n",
        "  word_idx = torch.repeat_interleave(word_idx, hidden_size, dim=2)\n",
        "  return word_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c02LofaoqacX"
      },
      "source": [
        "class Context_word_embedding_model(nn.Module):\n",
        "  def __init__(self, input_size, embed_size, hidden_size, num_layers, bidirectional, num_direction, dropout, device):\n",
        "    super(Context_word_embedding_model, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.num_direction = num_direction\n",
        "    self.embedding = nn.Embedding(input_size, embed_size,padding_idx= 1)\n",
        "    self.dimension = hidden_size*num_direction\n",
        "    self.device = device\n",
        "    self.drop = nn.Dropout(p =0.1)\n",
        "    self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, bidirectional = bidirectional, dropout = dropout)\n",
        "    self.fc = nn.Linear(self.dimension, self.dimension)\n",
        "    self.fc_pos = nn.Linear(self.dimension, 1)\n",
        "    self.cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, batch):\n",
        "    x = batch.s1.to(device=self.device)\n",
        "    s2 = batch.s2.to(device=self.device)\n",
        "    word_idx = batch.idx1.to(device=self.device)\n",
        "    word_idx2 = batch.idx2.to(device=self.device)\n",
        "    h0 = torch.zeros(self.num_layers*self.num_direction, x.size(1), self.hidden_size).to(self.device)\n",
        "    c0 = torch.zeros(self.num_layers*self.num_direction, x.size(1), self.hidden_size).to(self.device)\n",
        "    h02 = torch.zeros(self.num_layers*self.num_direction, s2.size(1), self.hidden_size).to(self.device)\n",
        "    c02 = torch.zeros(self.num_layers*self.num_direction, s2.size(1), self.hidden_size).to(self.device)\n",
        "\n",
        "    embedded_ = self.embedding(x)\n",
        "    embedded2_ = self.embedding(s2)\n",
        "    embedded = self.drop(embedded_)\n",
        "    embedded2 = self.drop(embedded2_)\n",
        "    outputs, _ = self.lstm(embedded, (h0,c0))\n",
        "    outputs2, __ = self.lstm(embedded2, (h02,c02))\n",
        "    word_idx = adjust_dim(word_idx, self.hidden_size*self.num_direction)\n",
        "    word_idx2 = adjust_dim(word_idx2, self.hidden_size*self.num_direction)\n",
        "    embed = torch.gather(outputs, 0, word_idx).squeeze()\n",
        "    embed2 = torch.gather(outputs2, 0, word_idx2).squeeze()\n",
        "    context_embedding = self.fc(embed)\n",
        "    context_embedding2 = self.fc(embed2)\n",
        "    out_sim = self.cos(context_embedding, context_embedding2)\n",
        "    out_final = self.sig(out_sim)\n",
        "    return out_final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8OWPlpFqvEX"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIeOU6NTN38Y",
        "outputId": "0441c669-9ac6-42c0-bd81-efb3aeea4c4b"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0n5N1Tyqb5s"
      },
      "source": [
        "input_size = len(sent.vocab)\n",
        "embedding_size = 300\n",
        "hidden_size = 200\n",
        "num_layers = 1\n",
        "bidirectional = False\n",
        "num_direction = 1\n",
        "dropout = 0\n",
        "model = Context_word_embedding_model(input_size, embedding_size, hidden_size, num_layers, bidirectional, num_direction, dropout, device).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GIhFHAyZyOM"
      },
      "source": [
        "checkpoint = torch.load('./results/lstm/mnli/best-lstm-mnli-params.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVo1rB-FZztM",
        "outputId": "d8dd8191-b4f2-4913-e975-6c4415da3112"
      },
      "source": [
        "checkpoint['accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(60.0313, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6zLF7cRqFZs",
        "outputId": "b12c5188-7a2e-4b9a-bf43-af84c1edb36e"
      },
      "source": [
        "model.load_state_dict(checkpoint['model_dict'])\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Context_word_embedding_model(\n",
              "  (embedding): Embedding(5739, 300, padding_idx=1)\n",
              "  (drop): Dropout(p=0.1, inplace=False)\n",
              "  (lstm): LSTM(300, 200)\n",
              "  (fc): Linear(in_features=200, out_features=200, bias=True)\n",
              "  (fc_pos): Linear(in_features=200, out_features=1, bias=True)\n",
              "  (cos): CosineSimilarity()\n",
              "  (sig): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vm8ENEgs7Zq"
      },
      "source": [
        "def test_model(test_iter, model):\n",
        "  #model.eval()\n",
        "  test_iter.init_epoch()\n",
        "  y_pred = torch.zeros(1)\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_iter):\n",
        "      answer = model(batch)\n",
        "      x = answer > 0.5\n",
        "      predictions = list(map(int,x))\n",
        "      predictions = torch.tensor(predictions).to(device)\n",
        "      if batch_idx == 0:\n",
        "        y_pred = predictions\n",
        "      else:\n",
        "        y_pred = torch.cat((y_pred,predictions))\n",
        "  y_pred = y_pred.to('cpu')\n",
        "  with open('output.txt', \"w\") as output_file:\n",
        "    for y in y_pred:\n",
        "      if y == 1:\n",
        "        Y_write = 'T'\n",
        "      elif y == 0:\n",
        "        Y_write = 'F'\n",
        "      output_file.write(\"%s\\n\" % Y_write)\n",
        "    output_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZN-_NGnurmL"
      },
      "source": [
        "test_model(test_iter, model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sh-Mw6cAIcH"
      },
      "source": [
        "## YOUR testing code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-IlAUkv7s1C",
        "outputId": "92cd3c78-5603-4d3c-adca-956889300730"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "# Your testing code must produce a file output.txt with predictions as T and F in each line\n",
        "\n",
        "## Final Evaluation \n",
        "# this is currently the same as dev.gold.txt\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
        "correct, total = 0., 0.\n",
        "for prediction, gold in zip(open('output.txt'), open('test.gold.txt')):\n",
        "  prediction, gold = prediction.strip(), gold.strip()\n",
        "  total += 1\n",
        "  if prediction == gold:\n",
        "    correct += 1\n",
        "\n",
        "## Report this as the final validation performance \n",
        "print('Performance = ', (correct/total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 11:41:40--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt [following]\n",
            "--2021-10-28 11:41:40--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/test.gold.txt\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1276 (1.2K) [text/plain]\n",
            "Saving to: ‘test.gold.txt’\n",
            "\n",
            "test.gold.txt       100%[===================>]   1.25K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-28 11:41:40 (64.7 MB/s) - ‘test.gold.txt’ saved [1276/1276]\n",
            "\n",
            "Performance =  0.48746081504702193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b74u5qXwscdQ",
        "outputId": "7f8d6a6a-6e4c-4896-fd90-633cf6ea73b5"
      },
      "source": [
        "!zip 2018EE10493_A.zip output.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output.txt (deflated 90%)\n"
          ]
        }
      ]
    }
  ]
}